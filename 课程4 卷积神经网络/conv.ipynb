{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积：\n",
    "1. padding \n",
    "  np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values = 0)\n",
    "  参数含义：(padding谁， 沿那个轴padding、padding多少， padding方式， padding的值)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X,pad):\n",
    "#     X_paded = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values = 0)    \n",
    "    X_paded = np.pad(X,(\n",
    "                        (0,0),       #样本数，不填充\n",
    "                        (pad,pad),   #图像高度,你可以视为上面填充x个，下面填充y个(x,y)\n",
    "                        (pad,pad),   #图像宽度,你可以视为左边填充x个，右边填充y个(x,y)\n",
    "                        (0,0)),      #通道数，不填充\n",
    "                        'constant', constant_values=0)      #连续一样的值填充\n",
    "    return X_paded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4,3,3,2)\n",
    "x_paded = zero_pad(x,2)\n",
    "#查看信息\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_paded.shape =\", x_paded.shape)\n",
    "print (\"x[1, 1] =\", x[1, 1])\n",
    "print (\"x_paded[1, 1] =\", x_paded[1, 1])\n",
    "\n",
    "#绘制图\n",
    "fig , axarr = plt.subplots(1,2)  #一行两列\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_paded')\n",
    "axarr[1].imshow(x_paded[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):  #  取出来的3维长方体和W的大小相同，做卷积，每个通道变成一个数，所有通道再相加，就是最后卷积值\n",
    "    s = np.multiply(a_slice_prev, W) + b\n",
    "    Z = np.sum(s)\n",
    "    return Z\n",
    "np.random.seed(1)\n",
    "\n",
    "#这里切片大小和过滤器大小相同\n",
    "a_slice_prev = np.random.randn(4,4,3)\n",
    "W = np.random.randn(4,4,3)\n",
    "b = np.random.randn(1,1,1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev,W,b)\n",
    "\n",
    "print(\"Z = \" + str(Z))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    pad = hparameters[\"pad\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    n_H = int((n_H_prev + 2 * pad - f) / stride) + 1\n",
    "    n_W = int((n_W_prev + 2 * pad - f) / stride) + 1\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    for i in range(m):\n",
    "        i_A_prev_pad = A_prev_pad[i] # 取出第i个padding的图像\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = stride * h\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = stride * w\n",
    "                    horiz_end = horiz_start + f\n",
    "                    a_slice_prev = i_A_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]  #取出小长条，所有通道的小图块堆叠成的\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[:, :, :, c], b[0, 0, 0, c])\n",
    "    \n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    cache = (A_prev, W, b, hparameters)                \n",
    "    return (Z , cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "\n",
    "hparameters = {\"pad\" : 2, \"stride\": 1}\n",
    "\n",
    "Z , cache_conv = conv_forward(A_prev,W,b,hparameters)\n",
    "\n",
    "print(\"np.mean(Z) = \", np.mean(Z))\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev,hparameters,mode=\"max\"):\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    n_H = int((n_H_prev - f) / stride) + 1\n",
    "    n_W = int((n_W_prev - f) / stride) + 1\n",
    "    n_C = n_C_prev  #池化层通道数不变，只是每个通道尺寸变小\n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "    for i in range(m):\n",
    "        i_image = A_prev[i,:,:,:] #取出第i个\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    h_start = h * stride\n",
    "                    h_end = h_start + f\n",
    "                    w_start = w * stride\n",
    "                    w_end = w_start + f\n",
    "                    a_slice_prev = A_prev[i, h_start:h_end, w_start:w_end, c]  # 取出小长条,进行pooling操作\n",
    "                    \n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_slice_prev)  #numpy基本函数，取最大值\n",
    "                    if mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_slice_prev)\n",
    "    assert(A.shape == (m, n_H, n_W, n_C)) \n",
    "    cache = (A_prev, hparameters)\n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2,4,4,3)\n",
    "hparameters = {\"f\":4 , \"stride\":1}\n",
    "\n",
    "A , cache = pool_forward(A_prev,hparameters,mode=\"max\")\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A =\", A)\n",
    "print(\"----------------------------\")\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A =\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积的反向传播原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as maimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import cnn_utils\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = cnn_utils.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(train_set_y_orig[:, index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1080)\n",
      "[5 0 2 ... 2 4 5]\n",
      "Y.shape =  (6, 1080)\n",
      "(1, 120)\n",
      "[0 0 0 5 1 0 3 1 5 1 5 1 3 1 1 3 5 4 0 4 5 4 2 5 3 5 4 2 1 2 3 1 0 3 1 1 0\n",
      " 4 2 3 0 3 0 2 3 1 2 2 0 3 4 1 2 0 4 0 4 0 4 4 5 5 2 4 4 5 0 1 3 5 0 4 1 2\n",
      " 3 4 3 5 1 5 2 0 1 4 2 4 4 1 4 5 5 0 0 5 5 5 3 3 5 2 2 2 0 2 5 3 0 2 3 4 1\n",
      " 3 2 4 2 2 1 3 1 3]\n",
      "Y.shape =  (6, 120)\n",
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_set_x_orig / 255\n",
    "X_test = test_set_x_orig / 255\n",
    "Y_train = cnn_utils.convert_to_one_hot(train_set_y_orig, 6).T\n",
    "Y_test = cnn_utils.convert_to_one_hot(test_set_y_orig, 6).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建placeholder\n",
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    X = tf.placeholder(tf.float32, [None, n_H0, n_W0, n_C0])  # 输入图片的数量不定，所以设置为None\n",
    "    Y = tf.placeholder(tf.float32, [None, n_y])   # 矩阵的行数代表输入图片的数量\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(?, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X , Y = create_placeholders(64,64,3,6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    w1 = tf.get_variable(\"W1\", [4, 4, 3, 8], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    w2 = tf.get_variable(\"W2\", [2, 2, 8, 16], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    parameters = {\"W1\":w1, \"W2\":w2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [ 0.00131723  0.1417614  -0.04434952  0.09197326  0.14984085 -0.03514394\n",
      " -0.06847463  0.05245192]\n",
      "W2 = [-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058\n",
      " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228\n",
      " -0.22779644 -0.1601823  -0.16117483 -0.10286498]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess_test:\n",
    "    parameters = initialize_parameters()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess_test.run(init)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"].eval()[1,1,1]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"].eval()[1,1,1]))\n",
    "\n",
    "    sess_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_exercise(env=py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
