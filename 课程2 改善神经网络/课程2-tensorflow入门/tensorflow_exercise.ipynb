{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import tf_utils\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "y_hat = tf.constant(36, name = \"y_hat\")\n",
    "y = tf.constant(39, name = \"y\")\n",
    "loss = tf.Variable((y_hat - y)**2, name = \"loss\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    print(session.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function():\n",
    "    np.random.seed(1)   \n",
    "    x = np.random.randn(3, 1)\n",
    "    w = np.random.randn(4, 3)\n",
    "    b = np.random.randn(4, 1)\n",
    "    \n",
    "    y = tf.matmul(w, x) + b\n",
    "    \n",
    "    session = tf.Session()\n",
    "    result = session.run(y)\n",
    "    session.close()\n",
    "    \n",
    "    return result\n",
    "print(\"result = \" +  str(linear_function()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    x = tf.placeholder(tf.float32, name = \"x\")\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(sigmoid, feed_dict = {x:z})\n",
    "    return result\n",
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(lables, C):\n",
    "    C = tf.constant(C, name = \"C\")\n",
    "    on_hot_matrix = tf.one_hot(indices = lables, depth = C, axis = 0)\n",
    "    with tf.Session() as sess:\n",
    "        one_hot = sess.run(on_hot_matrix)\n",
    "    return one_hot\n",
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels,C=4)\n",
    "print(str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：\n",
    "1. tf框架中，各种运算的定义仅仅是定义的是计算图，真正要出结果，要使用session.\n",
    "2. tf.placeholder定义的变量只是一个空架子，在run含有这样的变量的式子时，需要使用feed_dict给值\n",
    "3. tf.one_hot：indices表示向量第几个数是1，depth是分类数，也是矩阵的行数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig , Y_train_orig , X_test_orig , Y_test_orig , classes = tf_utils.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 11\n",
    "plt.imshow(X_train_orig[index])\n",
    "print(\"Y = \" + str(np.squeeze(Y_train_orig[:,index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "X_train = X_train_flatten / 255\n",
    "X_test = X_test_flatten / 255\n",
    "\n",
    "Y_train = tf_utils.convert_to_one_hot(Y_train_orig,6)\n",
    "Y_test = tf_utils.convert_to_one_hot(Y_test_orig, 6)\n",
    "print(\"训练集样本数 = \" + str(X_train.shape[1]))\n",
    "print(\"测试集样本数 = \" + str(X_test.shape[1]))\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"Y_train.shape: \" + str(Y_train.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))\n",
    "print(\"Y_test.shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x,n_y):\n",
    "    X = tf.placeholder(tf.float32, [n_x, None], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None], name = \"Y\")\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_placeholders(12288, 6)\n",
    "print(\"X = \" + str(X))\n",
    "print(\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    w1 = tf.get_variable(\"W1\", [25, 12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25, 1], initializer = tf.zeros_initializer())\n",
    "    w2 = tf.get_variable(\"W2\", [12, 25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12, 1], initializer = tf.zeros_initializer())\n",
    "    w3 = tf.get_variable(\"w3\", [6, 12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [6, 1], initializer = tf.zeros_initializer())\n",
    "    parameters = {\n",
    "        \"W1\":w1,\n",
    "        \"b1\":b1,\n",
    "        \"W2\":w2,\n",
    "        \"b2\":b2,\n",
    "        \"W3\":w3,\n",
    "        \"b3\":b3\n",
    "    }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #用于清除默认图形堆栈并重置全局默认图形。 \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    w1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    w2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    w3 = parameters[\"W3\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    \n",
    "    Z1 = tf.matmul(w1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.matmul(w2, A1) + b2\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.matmul(w3, A2) + b3\n",
    "    #A3 = tf.nn.relu(Z3)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #用于清除默认图形堆栈并重置全局默认图形。 \n",
    "with tf.Session() as sess:\n",
    "    X,Y = create_placeholders(12288,6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "    print(\"Z3 = \" + str(Z3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3,Y):\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X,Y = create_placeholders(12288,6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train,Y_train,X_test,Y_test,learning_rate=0.0001,num_epochs=1500,minibatch_size=32,print_cost=True,is_plot=True):\n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3\n",
    "    (n_x, m) = X_train.shape\n",
    "    n_y = Y_train.shape[0]\n",
    "    costs = []\n",
    "    X,Y = create_placeholders(n_x, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0\n",
    "            num_minibatches = int(m / minibatch_size)\n",
    "            seed = seed + 1\n",
    "            minibatches = tf_utils.random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _, minibatch_cost = sess.run([optimizer, cost], feed_dict = {X:minibatch_X, Y:minibatch_Y})\n",
    "                epoch_cost = epoch_cost + minibatch_cost / num_minibatches  #还不懂，为什么要除以batch的数量\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                if print_cost and epoch % 100 == 0:\n",
    "                    print(\"epoch = {}\\t|epoch_cost = {}\".format(epoch, epoch_cost))\n",
    "            \n",
    "        if is_plot:\n",
    "            plt.plot(np.squeeze(costs))\n",
    "            plt.ylabel(\"cost\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "            plt.show()\n",
    "\n",
    "                          \n",
    "        parameters = sess.run(parameters)  #需要使用run取出最终的参数值\n",
    "        corrent_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))  # tf.argmax沿着某个轴找最大值的索引，默认是0轴。\n",
    "        accuracy = tf.reduce_mean(tf.cast(corrent_prediction, \"float\"))\n",
    "                          \n",
    "        print(\"accuracy_train:\", accuracy.eval({X:X_train, Y:Y_train}))\n",
    "        print(\"accuracy_test: \", accuracy.eval({X:X_test, Y:Y_test}))\n",
    "        # accuracy.eval({X:X_train, Y:Y_train})等价于sess.run(accuracy, feed_dict = {X:X_train, Y:Y_train}).\n",
    "        return parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备工作：创建X、Y的占位符，只需指定特征维度，初始化参数\n",
    "1.前向传播，获得Z3\n",
    "2.计算loss\n",
    "3.准备好优化器，反向传播用\n",
    "4.创建session,优化loss：\n",
    "   4.1 每个epoch前，准备好随机的小批量数据集\n",
    "   4.2 关键代码：sess.run([optimizer, cost], feed_dict = {X:minibatch_X, Y:minibatch_Y})。可以run了之后参数就更新到最优，也可以得到cost了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始时间\n",
    "start_time = time.clock()\n",
    "#开始训练\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)\n",
    "#结束时间\n",
    "end_time = time.clock()\n",
    "#计算时差\n",
    "print(\"CPU的执行时间 = \" + str(end_time - start_time) + \" 秒\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_exercise(env=py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
